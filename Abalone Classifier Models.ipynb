{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Import Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0708 17:35:13.482460 139646456252032 __init__.py:308] Limited tf.compat.v2.summary API due to missing TensorBoard installation.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import math\n",
    "from IPython import display\n",
    "from matplotlib import cm\n",
    "from matplotlib import gridspec\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import metrics\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.data import Dataset\n",
    "tf.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Read CSV File and Randomize**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sex</th>\n",
       "      <th>length</th>\n",
       "      <th>diameter</th>\n",
       "      <th>height</th>\n",
       "      <th>whole-weight</th>\n",
       "      <th>shucked-weight</th>\n",
       "      <th>viscera-weight</th>\n",
       "      <th>shell-weight</th>\n",
       "      <th>rings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2511</th>\n",
       "      <td>2</td>\n",
       "      <td>0.425</td>\n",
       "      <td>0.310</td>\n",
       "      <td>0.105</td>\n",
       "      <td>0.3650</td>\n",
       "      <td>0.1590</td>\n",
       "      <td>0.0825</td>\n",
       "      <td>0.105</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>558</th>\n",
       "      <td>1</td>\n",
       "      <td>0.660</td>\n",
       "      <td>0.530</td>\n",
       "      <td>0.170</td>\n",
       "      <td>1.3260</td>\n",
       "      <td>0.5190</td>\n",
       "      <td>0.2625</td>\n",
       "      <td>0.440</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3659</th>\n",
       "      <td>0</td>\n",
       "      <td>0.545</td>\n",
       "      <td>0.410</td>\n",
       "      <td>0.140</td>\n",
       "      <td>0.7370</td>\n",
       "      <td>0.3490</td>\n",
       "      <td>0.1500</td>\n",
       "      <td>0.212</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3856</th>\n",
       "      <td>2</td>\n",
       "      <td>0.335</td>\n",
       "      <td>0.255</td>\n",
       "      <td>0.085</td>\n",
       "      <td>0.1785</td>\n",
       "      <td>0.0710</td>\n",
       "      <td>0.0405</td>\n",
       "      <td>0.055</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>1</td>\n",
       "      <td>0.630</td>\n",
       "      <td>0.480</td>\n",
       "      <td>0.160</td>\n",
       "      <td>1.1990</td>\n",
       "      <td>0.5265</td>\n",
       "      <td>0.3350</td>\n",
       "      <td>0.315</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      sex  length  diameter  height  whole-weight  shucked-weight  \\\n",
       "2511    2   0.425     0.310   0.105        0.3650          0.1590   \n",
       "558     1   0.660     0.530   0.170        1.3260          0.5190   \n",
       "3659    0   0.545     0.410   0.140        0.7370          0.3490   \n",
       "3856    2   0.335     0.255   0.085        0.1785          0.0710   \n",
       "188     1   0.630     0.480   0.160        1.1990          0.5265   \n",
       "\n",
       "      viscera-weight  shell-weight  rings  \n",
       "2511          0.0825         0.105      6  \n",
       "558           0.2625         0.440     13  \n",
       "3659          0.1500         0.212      9  \n",
       "3856          0.0405         0.055      9  \n",
       "188           0.3350         0.315     11  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abalone_dataframe = pd.read_csv(\"abalone.csv\")\n",
    "abalone_dataframe.dropna()\n",
    "abalone_dataframe = abalone_dataframe.reindex(np.random.permutation(abalone_dataframe.index))\n",
    "#Male 0, Female 1, Infant 2\n",
    "mapping = {\"M\" : 0, \"F\" : 1, \"I\" : 2}\n",
    "abalone_dataframe = abalone_dataframe.replace({\"sex\" : mapping})\n",
    "abalone_dataframe.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create Training and Validation Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_features(dataframe, selected_features):\n",
    "    output_features = dataframe[selected_features]\n",
    "    \n",
    "    return output_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Single Panda Series\n",
    "def preprocess_targets(dataframe, selected_target):\n",
    "    output_targets = dataframe[selected_target]\n",
    "    \n",
    "    return output_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "training_split = int(0.6 * len(abalone_dataframe))\n",
    "validations_split = int(0.3 * len(abalone_dataframe))\n",
    "\n",
    "selected_features = [\n",
    "    \"length\",\n",
    "    \"diameter\",\n",
    "    \"height\",\n",
    "    \"whole-weight\",\n",
    "    #\"shucked-weight\",\n",
    "    #\"viscera-weight\",\n",
    "    #\"shell-weight\",\n",
    "    #\"rings\"\n",
    "]\n",
    "\n",
    "selected_target = \"sex\"\n",
    "\n",
    "#Feature Columns\n",
    "feature_columns = {\n",
    "    tf.feature_column.numeric_column(\"length\"),\n",
    "    tf.feature_column.numeric_column(\"diameter\"),\n",
    "    tf.feature_column.numeric_column(\"height\"),\n",
    "    tf.feature_column.numeric_column(\"whole-weight\"),\n",
    "    #tf.feature_column.numeric_column(\"shucked-weight\"),\n",
    "    #tf.feature_column.numeric_column(\"viscera-weight\"),\n",
    "    #tf.feature_column.numeric_column(\"shell-weight\"),\n",
    "    #tf.feature_column.numeric_column(\"rings\")\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Panda Data\n",
    "training_examples = preprocess_features(abalone_dataframe.iloc[0:training_split], selected_features)\n",
    "training_targets = preprocess_targets(abalone_dataframe.iloc[0:training_split], selected_target)\n",
    "validation_examples = preprocess_features(abalone_dataframe.iloc[training_split:training_split + validations_split], selected_features)\n",
    "validation_targets = preprocess_targets(abalone_dataframe.iloc[training_split:training_split + validations_split], selected_target)\n",
    "#Do not touch until end!\n",
    "test_examples = preprocess_features(abalone_dataframe.iloc[training_split + validations_split:], selected_features)\n",
    "test_targets = preprocess_targets(abalone_dataframe.iloc[training_split + validations_split:], selected_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Training Functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Return next batch (Of type of Tensorflow Dataset)\n",
    "def input_fn(features, targets, batch_size=1, shuffle=True, num_epochs=None):\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((dict(features), targets))\n",
    "    \n",
    "    if(shuffle):\n",
    "        dataset = dataset.shuffle(1000)\n",
    "    \n",
    "    dataset = dataset.batch(batch_size).repeat(num_epochs)\n",
    "    \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_linear_classifier_model(\n",
    "    learning_rate,\n",
    "    steps,\n",
    "    batch_size,\n",
    "    feature_columns,\n",
    "    n_classes,\n",
    "    training_examples,\n",
    "    training_targets,\n",
    "    validation_examples,\n",
    "    validation_targets):\n",
    "    \n",
    "    periods = 10\n",
    "    steps_per_period = steps / periods\n",
    "    \n",
    "    #Initialize Linear Classifier\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
    "    optimizer = tf.contrib.estimator.clip_gradients_by_norm(optimizer, 5.0)\n",
    "    linear_classifier = tf.estimator.LinearClassifier(\n",
    "        feature_columns=feature_columns,\n",
    "        n_classes=n_classes,\n",
    "        optimizer=optimizer\n",
    "    )\n",
    "    \n",
    "    #Training Functions\n",
    "    training_input_fn = lambda: input_fn(\n",
    "        training_examples,\n",
    "        training_targets,\n",
    "        batch_size=batch_size) \n",
    "    predict_training_input_fn = lambda: input_fn(\n",
    "        training_examples, \n",
    "        training_targets, \n",
    "        num_epochs=1, \n",
    "        shuffle=False)\n",
    "    \n",
    "    #Validation Function\n",
    "    predict_validation_input_fn = lambda: input_fn(\n",
    "        validation_examples, \n",
    "        validation_targets, \n",
    "        num_epochs=1, \n",
    "        shuffle=False)\n",
    "    \n",
    "    #Train Model\n",
    "    training_log_losses = []\n",
    "    validation_log_losses = []\n",
    "    \n",
    "    print(\"Training Model\")\n",
    "    for period in range(0, periods):\n",
    "        linear_classifier.train(\n",
    "            input_fn=training_input_fn,\n",
    "            #Manually break total steps by 10\n",
    "            steps=steps_per_period\n",
    "        )\n",
    "        \n",
    "        #Use Sklearn to calculate Log Loss\n",
    "        training_probabilities = linear_classifier.predict(input_fn=predict_training_input_fn)\n",
    "        training_probabilities = np.array([item['probabilities'] for item in training_probabilities])\n",
    "        training_log_loss = metrics.log_loss(training_targets, training_probabilities)\n",
    "        \n",
    "        #Calculate Validation Log Loss\n",
    "        validation_probabilities = linear_classifier.predict(input_fn=predict_validation_input_fn)\n",
    "        validation_probabilities = np.array([item['probabilities'] for item in validation_probabilities])\n",
    "        validation_log_loss = metrics.log_loss(validation_targets, validation_probabilities)\n",
    "        \n",
    "        #Append Losses\n",
    "        training_log_losses.append(training_log_loss)\n",
    "        validation_log_losses.append(validation_log_loss)\n",
    "        \n",
    "        print(\"Period:\", period, \"Training Log Loss:\", training_log_loss, \"Validation Log Loss:\", validation_log_loss)\n",
    "    print(\"Training Finished\")\n",
    "    \n",
    "    #Graph\n",
    "    plt.ylabel(\"Log Loss\")\n",
    "    plt.xlabel(\"Periods\")\n",
    "    plt.title(\"Log Loss vs. Periods\")\n",
    "    plt.tight_layout()\n",
    "    plt.plot(training_log_losses, label=\"training\")\n",
    "    plt.plot(validation_log_losses, label=\"validation\")\n",
    "    plt.legend()\n",
    "    \n",
    "    return linear_classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_dnn_classifier_model(\n",
    "    learning_rate,\n",
    "    steps,\n",
    "    batch_size,\n",
    "    hidden_units,\n",
    "    feature_columns,\n",
    "    n_classes,\n",
    "    training_examples,\n",
    "    training_targets,\n",
    "    validation_examples,\n",
    "    validation_targets):\n",
    "\n",
    "    periods = 10\n",
    "    steps_per_period = steps / periods\n",
    "    \n",
    "    #Initialize DNN Regressor\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
    "    optimizer = tf.contrib.estimator.clip_gradients_by_norm(optimizer, 5.0)\n",
    "    dnn_classifier = tf.estimator.DNNClassifier(\n",
    "        feature_columns=feature_columns,\n",
    "        n_classes=n_classes,\n",
    "        hidden_units=hidden_units,\n",
    "        optimizer=optimizer,\n",
    "    )\n",
    "    \n",
    "    #Training Functions\n",
    "    training_input_fn = lambda: input_fn(\n",
    "        training_examples,\n",
    "        training_targets,\n",
    "        batch_size=batch_size) \n",
    "    predict_training_input_fn = lambda: input_fn(\n",
    "        training_examples, \n",
    "        training_targets, \n",
    "        num_epochs=1, \n",
    "        shuffle=False)\n",
    "    \n",
    "    #Validation Function\n",
    "    predict_validation_input_fn = lambda: input_fn(\n",
    "        validation_examples, \n",
    "        validation_targets, \n",
    "        num_epochs=1, \n",
    "        shuffle=False)\n",
    "    \n",
    "    #Train Model\n",
    "    training_log_losses = []\n",
    "    validation_log_losses = []\n",
    "    \n",
    "    print(\"Training Model\")\n",
    "    for period in range(0, periods):\n",
    "        dnn_classifier.train(\n",
    "            input_fn=training_input_fn,\n",
    "            #Manually break total steps by 10\n",
    "            steps=steps_per_period\n",
    "        )\n",
    "        \n",
    "        #Use Sklearn to calculate Log Loss\n",
    "        training_probabilities = dnn_classifier.predict(input_fn=predict_training_input_fn)\n",
    "        training_probabilities = np.array([item['probabilities'] for item in training_probabilities])\n",
    "        training_log_loss = metrics.log_loss(training_targets, training_probabilities)\n",
    "        \n",
    "        #Calculate Validation Log Loss\n",
    "        validation_probabilities = dnn_classifier.predict(input_fn=predict_validation_input_fn)\n",
    "        validation_probabilities = np.array([item['probabilities'] for item in validation_probabilities])\n",
    "        validation_log_loss = metrics.log_loss(validation_targets, validation_probabilities)\n",
    "        \n",
    "        #Append Losses\n",
    "        training_log_losses.append(training_log_loss)\n",
    "        validation_log_losses.append(validation_log_loss)\n",
    "        \n",
    "        print(\"Period:\", period, \"Training Log Loss:\", training_log_loss, \"Validation Log Loss:\", validation_log_loss)\n",
    "    print(\"Training Finished\")\n",
    "    \n",
    "    #Graph\n",
    "    plt.ylabel(\"Log Loss\")\n",
    "    plt.xlabel(\"Periods\")\n",
    "    plt.title(\"Log Loss vs. Periods\")\n",
    "    plt.tight_layout()\n",
    "    plt.plot(training_log_losses, label=\"training\")\n",
    "    plt.plot(validation_log_losses, label=\"validation\")\n",
    "    plt.legend()\n",
    "    \n",
    "    return dnn_classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0708 17:35:19.064284 139646456252032 lazy_loader.py:50] \n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "W0708 17:35:19.065380 139646456252032 estimator.py:1811] Using temporary folder as model directory: /tmp/tmpibidm09f\n",
      "W0708 17:35:19.073912 139646456252032 deprecation.py:323] From /usr/lib/python3.7/site-packages/tensorflow/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0708 17:35:19.466544 139646456252032 deprecation.py:323] From /usr/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/canned/linear.py:308: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "W0708 17:35:19.709558 139646456252032 deprecation.py:323] From /usr/lib/python3.7/site-packages/tensorflow/python/ops/clip_ops.py:286: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "W0708 17:35:21.827399 139646456252032 deprecation.py:323] From /usr/lib/python3.7/site-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Period: 0 Training Log Loss: 1.0527333870042541 Validation Log Loss: 1.0583133091473713\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0708 17:35:25.485152 139646456252032 deprecation.py:323] From /usr/lib/python3.7/site-packages/tensorflow/python/training/saver.py:1066: get_checkpoint_mtimes (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file utilities to get mtimes.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Period: 1 Training Log Loss: 1.0264991774429633 Validation Log Loss: 1.0342154817779066\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0708 17:35:31.380033 139646456252032 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 3840 vs previous value: 3840. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n",
      "W0708 17:35:31.823383 139646456252032 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 4154 vs previous value: 4154. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Period: 2 Training Log Loss: 1.00520447110616 Validation Log Loss: 1.0146516470174645\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0708 17:35:35.662608 139646456252032 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 4791 vs previous value: 4791. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Period: 3 Training Log Loss: 0.9875499767393278 Validation Log Loss: 0.998486208325848\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0708 17:35:41.528778 139646456252032 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 7377 vs previous value: 7377. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n",
      "W0708 17:35:41.620564 139646456252032 deprecation.py:323] From /usr/lib/python3.7/site-packages/tensorflow/python/training/saver.py:960: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to delete files with this prefix.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Period: 4 Training Log Loss: 0.9726115903755426 Validation Log Loss: 0.9850960130322388\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0708 17:35:46.011996 139646456252032 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 7996 vs previous value: 7996. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Period: 5 Training Log Loss: 0.9600966862935784 Validation Log Loss: 0.9739556253099099\n",
      "Period: 6 Training Log Loss: 0.9495708051911375 Validation Log Loss: 0.9647581631054616\n",
      "Period: 7 Training Log Loss: 0.940548494993356 Validation Log Loss: 0.9571583979575042\n",
      "Period: 8 Training Log Loss: 0.9329354292924938 Validation Log Loss: 0.9507169625993167\n",
      "Period: 9 Training Log Loss: 0.926364239557971 Validation Log Loss: 0.9454277799972418\n",
      "Training Finished\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "linear_classifier = train_linear_classifier_model(\n",
    "    learning_rate=0.0001,\n",
    "    steps=15000,\n",
    "    batch_size=20,\n",
    "    feature_columns=feature_columns,\n",
    "    n_classes=3,\n",
    "    training_examples=training_examples,\n",
    "    training_targets=training_targets,\n",
    "    validation_examples=validation_examples,\n",
    "    validation_targets=validation_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0708 17:36:10.512669 139646456252032 estimator.py:1811] Using temporary folder as model directory: /tmp/tmpr3t3jb1k\n",
      "W0708 17:36:10.575408 139646456252032 deprecation.py:506] From /usr/lib/python3.7/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Model\n",
      "Period: 0 Training Log Loss: 1.0955314433584191 Validation Log Loss: 1.098375525364187\n",
      "Period: 1 Training Log Loss: 1.0955476566304803 Validation Log Loss: 1.0982285308914002\n",
      "Period: 2 Training Log Loss: 1.0955485202794253 Validation Log Loss: 1.09823453012506\n",
      "Period: 3 Training Log Loss: 1.0955363802926976 Validation Log Loss: 1.0983746357660529\n",
      "Period: 4 Training Log Loss: 1.0955436971315078 Validation Log Loss: 1.0982469031074384\n",
      "Period: 5 Training Log Loss: 1.0955362142987568 Validation Log Loss: 1.0983838573609555\n",
      "Period: 6 Training Log Loss: 1.0955532884607293 Validation Log Loss: 1.0983776050572955\n",
      "Period: 7 Training Log Loss: 1.0955509708009523 Validation Log Loss: 1.0984884669851134\n",
      "Period: 8 Training Log Loss: 1.0955654785619768 Validation Log Loss: 1.0981890176261604\n",
      "Period: 9 Training Log Loss: 1.0955834269333342 Validation Log Loss: 1.098072832998807\n",
      "Training Finished\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "dnn_classifier = train_dnn_classifier_model(\n",
    "    learning_rate=0.001,\n",
    "    steps=15000,\n",
    "    batch_size=20,\n",
    "    hidden_units=[5, 4, 3],\n",
    "    feature_columns=feature_columns,\n",
    "    n_classes=3,\n",
    "    training_examples=training_examples,\n",
    "    training_targets=training_targets,\n",
    "    validation_examples=validation_examples,\n",
    "    validation_targets=validation_targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Test Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_classifier_model(model, test_examples, test_targets):\n",
    "    predict_test_input_fn = lambda: input_fn(\n",
    "        test_examples, \n",
    "        test_targets, \n",
    "        num_epochs=1, \n",
    "        shuffle=False)\n",
    "    \n",
    "    test_probabilities = model.predict(input_fn=predict_test_input_fn)\n",
    "    test_probabilities = np.array([item['probabilities'] for item in test_probabilities])\n",
    "\n",
    "    for probabilities, label in zip(test_probabilities, test_targets): \n",
    "        if(max(probabilities) == probabilities[label]):\n",
    "            print(\"Probability:\", probabilities, \"Label:\", label)\n",
    "        else:\n",
    "            print(\"Probability:\", probabilities, \"Label:\", label, \"Wrong\")\n",
    "    \n",
    "    evaluation = model.evaluate(input_fn=predict_test_input_fn)\n",
    "    print(evaluation)\n",
    "    \n",
    "    return test_probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability: [0.2638252  0.21993162 0.5162431 ] Label: 2\n",
      "Probability: [0.20673718 0.17136282 0.62189996] Label: 2\n",
      "Probability: [0.41634566 0.35365984 0.22999458] Label: 2 Wrong\n",
      "Probability: [0.30149147 0.25238636 0.4461222 ] Label: 2\n",
      "Probability: [0.36124238 0.3045594  0.3341982 ] Label: 0\n",
      "Probability: [0.2156662  0.17895557 0.60537815] Label: 2\n",
      "Probability: [0.30091795 0.25190905 0.447173  ] Label: 1 Wrong\n",
      "Probability: [0.51189613 0.4481824  0.03992148] Label: 0\n",
      "Probability: [0.2814989 0.2352094 0.4832917] Label: 1 Wrong\n",
      "Probability: [0.31636852 0.2653574  0.41827407] Label: 0 Wrong\n",
      "Probability: [0.51174337 0.44796413 0.04029246] Label: 0\n",
      "Probability: [0.33259073 0.2794288  0.38798043] Label: 0 Wrong\n",
      "Probability: [0.45501685 0.389242   0.15574118] Label: 1 Wrong\n",
      "Probability: [0.35111117 0.29558736 0.35330147] Label: 0 Wrong\n",
      "Probability: [0.3122626  0.26173273 0.42600468] Label: 1 Wrong\n",
      "Probability: [0.44015297 0.3755331  0.18431392] Label: 2 Wrong\n",
      "Probability: [0.21404864 0.1775521  0.6083992 ] Label: 2\n",
      "Probability: [0.47418168 0.40773645 0.11808185] Label: 0\n",
      "Probability: [0.44446018 0.37950367 0.1760362 ] Label: 1 Wrong\n",
      "Probability: [0.42586306 0.36272442 0.21141252] Label: 0\n",
      "Probability: [0.4040152  0.3426576  0.25332722] Label: 2 Wrong\n",
      "Probability: [0.31898904 0.26746216 0.4135488 ] Label: 0 Wrong\n",
      "Probability: [0.47485894 0.40844378 0.11669739] Label: 1 Wrong\n",
      "Probability: [0.4148887  0.35238376 0.23272754] Label: 2 Wrong\n",
      "Probability: [0.4122567  0.3499706  0.23777267] Label: 0\n",
      "Probability: [0.2414542  0.20084639 0.5576994 ] Label: 2\n",
      "Probability: [0.42924526 0.365438   0.2053167 ] Label: 0\n",
      "Probability: [0.46829554 0.40210962 0.12959482] Label: 1 Wrong\n",
      "Probability: [0.49564117 0.4295832  0.07477564] Label: 0\n",
      "Probability: [0.38267237 0.32349566 0.29383194] Label: 2 Wrong\n",
      "Probability: [0.47735256 0.41088817 0.11175934] Label: 0\n",
      "Probability: [0.32987452 0.27696323 0.39316225] Label: 1 Wrong\n",
      "Probability: [0.43183002 0.36800483 0.2001652 ] Label: 1 Wrong\n",
      "Probability: [0.5141037  0.45086998 0.03502624] Label: 0\n",
      "Probability: [0.22350672 0.18557873 0.5909146 ] Label: 2\n",
      "Probability: [0.24004836 0.1996605  0.5602912 ] Label: 2\n",
      "Probability: [0.2931501  0.245225   0.46162495] Label: 0 Wrong\n",
      "Probability: [0.31898153 0.2675855  0.413433  ] Label: 2\n",
      "Probability: [0.21024717 0.1743366  0.6154163 ] Label: 2\n",
      "Probability: [0.46016085 0.39412552 0.14571363] Label: 0\n",
      "Probability: [0.40222535 0.34126148 0.2565132 ] Label: 0\n",
      "Probability: [0.3525067  0.2969623  0.35053104] Label: 0\n",
      "Probability: [0.2973671  0.24886091 0.45377195] Label: 2\n",
      "Probability: [0.22761978 0.18909945 0.5832808 ] Label: 2\n",
      "Probability: [0.43580258 0.37133384 0.19286357] Label: 1 Wrong\n",
      "Probability: [0.40530685 0.3436155  0.2510777 ] Label: 2 Wrong\n",
      "Probability: [0.39764503 0.3368646  0.26549035] Label: 2 Wrong\n",
      "Probability: [0.45205283 0.38664576 0.16130134] Label: 0\n",
      "Probability: [0.2701245  0.22536364 0.5045119 ] Label: 0 Wrong\n",
      "Probability: [0.20135292 0.16681632 0.63183075] Label: 0 Wrong\n",
      "Probability: [0.33473122 0.2813836  0.3838852 ] Label: 2\n",
      "Probability: [0.32839847 0.27572656 0.395875  ] Label: 2\n",
      "Probability: [0.28916925 0.24168096 0.46914977] Label: 2\n",
      "Probability: [0.41645962 0.35371712 0.22982332] Label: 1 Wrong\n",
      "Probability: [0.4807676  0.41436172 0.10487068] Label: 1 Wrong\n",
      "Probability: [0.39073768 0.33069563 0.27856678] Label: 2 Wrong\n",
      "Probability: [0.3781284  0.31946725 0.30240437] Label: 0\n",
      "Probability: [0.26512268 0.22110452 0.51377285] Label: 2\n",
      "Probability: [0.35711783 0.300912   0.34197015] Label: 2 Wrong\n",
      "Probability: [0.39721322 0.33642912 0.26635766] Label: 1 Wrong\n",
      "Probability: [0.5224234  0.46614212 0.01143444] Label: 1 Wrong\n",
      "Probability: [0.44840464 0.38321915 0.16837622] Label: 1 Wrong\n",
      "Probability: [0.38923624 0.32949722 0.28126657] Label: 0\n",
      "Probability: [0.2212465  0.18365051 0.595103  ] Label: 2\n",
      "Probability: [0.5197387  0.45990616 0.02035514] Label: 0\n",
      "Probability: [0.47027528 0.40399152 0.12573321] Label: 0\n",
      "Probability: [0.45695594 0.39110824 0.15193586] Label: 1 Wrong\n",
      "Probability: [0.3557986  0.29969558 0.34450582] Label: 1 Wrong\n",
      "Probability: [0.49908152 0.43331364 0.06760482] Label: 0\n",
      "Probability: [0.5059379  0.4408431  0.05321906] Label: 1 Wrong\n",
      "Probability: [0.47425875 0.40778175 0.11795957] Label: 0\n",
      "Probability: [0.2655982  0.22147514 0.5129267 ] Label: 2\n",
      "Probability: [0.35121298 0.29572746 0.35305956] Label: 0 Wrong\n",
      "Probability: [0.3724278  0.3143857  0.31318653] Label: 1 Wrong\n",
      "Probability: [0.5019407  0.43635604 0.06170325] Label: 0\n",
      "Probability: [0.4663103  0.40011787 0.1335718 ] Label: 2 Wrong\n",
      "Probability: [0.47056025 0.40425617 0.12518355] Label: 1 Wrong\n",
      "Probability: [0.28549263 0.23850249 0.47600493] Label: 0 Wrong\n",
      "Probability: [0.44877586 0.383578   0.16764617] Label: 0\n",
      "Probability: [0.42314783 0.35970813 0.21714404] Label: 0\n",
      "Probability: [0.45672858 0.39084107 0.15243033] Label: 1 Wrong\n",
      "Probability: [0.4932072  0.4269605  0.07983222] Label: 1 Wrong\n",
      "Probability: [0.24056377 0.20010288 0.5593333 ] Label: 0 Wrong\n",
      "Probability: [0.34356433 0.2890617  0.36737394] Label: 2\n",
      "Probability: [0.4415529  0.3769376  0.18150952] Label: 0\n",
      "Probability: [0.28873685 0.24130502 0.46995813] Label: 2\n",
      "Probability: [0.45046785 0.3849569  0.16457523] Label: 1 Wrong\n",
      "Probability: [0.45518267 0.38951597 0.1553013 ] Label: 0\n",
      "Probability: [0.49454734 0.42833668 0.07711592] Label: 1 Wrong\n",
      "Probability: [0.42036158 0.3571392  0.22249918] Label: 1 Wrong\n",
      "Probability: [0.38882837 0.32895792 0.28221372] Label: 2 Wrong\n",
      "Probability: [0.50926363 0.4449663  0.04577015] Label: 1 Wrong\n",
      "Probability: [0.3847638  0.32538474 0.28985146] Label: 0\n",
      "Probability: [0.40189508 0.34081045 0.25729454] Label: 1 Wrong\n",
      "Probability: [0.2786833  0.23269413 0.48862252] Label: 2\n",
      "Probability: [0.48062432 0.41406858 0.10530716] Label: 1 Wrong\n",
      "Probability: [0.39169726 0.33157402 0.2767287 ] Label: 1 Wrong\n",
      "Probability: [0.4495774  0.384282   0.16614053] Label: 1 Wrong\n",
      "Probability: [0.45166823 0.38609225 0.16223958] Label: 1 Wrong\n",
      "Probability: [0.49239218 0.42633635 0.08127148] Label: 0\n",
      "Probability: [0.31624883 0.26513076 0.4186204 ] Label: 2\n",
      "Probability: [0.33898175 0.28500038 0.37601787] Label: 2\n",
      "Probability: [0.35484347 0.29896882 0.3461877 ] Label: 2 Wrong\n",
      "Probability: [0.44009686 0.37559184 0.18431126] Label: 1 Wrong\n",
      "Probability: [0.37919152 0.32045126 0.30035716] Label: 1 Wrong\n",
      "Probability: [0.22154073 0.18391779 0.5945415 ] Label: 0 Wrong\n",
      "Probability: [0.26018572 0.21678272 0.52303153] Label: 2\n",
      "Probability: [0.40450716 0.34313175 0.25236112] Label: 0\n",
      "Probability: [0.31537622 0.26440182 0.42022198] Label: 1 Wrong\n",
      "Probability: [0.45733866 0.39150372 0.15115768] Label: 1 Wrong\n",
      "Probability: [0.34671462 0.2917607  0.36152464] Label: 0 Wrong\n",
      "Probability: [0.3873801  0.32758132 0.2850386 ] Label: 1 Wrong\n",
      "Probability: [0.40365407 0.34258273 0.25376317] Label: 0\n",
      "Probability: [0.3768918  0.3183701  0.30473807] Label: 0\n",
      "Probability: [0.34200484 0.28776643 0.37022877] Label: 0 Wrong\n",
      "Probability: [0.21255146 0.17629112 0.6111574 ] Label: 0 Wrong\n",
      "Probability: [0.21456426 0.17798786 0.60744786] Label: 2\n",
      "Probability: [0.2412908  0.20072068 0.5579886 ] Label: 2\n",
      "Probability: [0.47189173 0.40551072 0.12259757] Label: 0\n",
      "Probability: [0.5045248  0.43920758 0.05626766] Label: 1 Wrong\n",
      "Probability: [0.38790524 0.32824975 0.28384504] Label: 2 Wrong\n",
      "Probability: [0.2581806  0.21513878 0.5266806 ] Label: 2\n",
      "Probability: [0.43864855 0.37403643 0.18731493] Label: 0\n",
      "Probability: [0.51252955 0.448818   0.03865243] Label: 1 Wrong\n",
      "Probability: [0.45391545 0.38823697 0.15784755] Label: 0\n",
      "Probability: [0.2329094  0.19352558 0.57356507] Label: 2\n",
      "Probability: [0.21283758 0.17654642 0.61061597] Label: 2\n",
      "Probability: [0.19200917 0.15892562 0.6490652 ] Label: 2\n",
      "Probability: [0.43760628 0.37324846 0.18914516] Label: 1 Wrong\n",
      "Probability: [0.50379395 0.43870935 0.05749676] Label: 1 Wrong\n",
      "Probability: [0.49178246 0.42531222 0.08290533] Label: 1 Wrong\n",
      "Probability: [0.22402065 0.18597944 0.5899999 ] Label: 2\n",
      "Probability: [0.30041754 0.25145108 0.44813132] Label: 2\n",
      "Probability: [0.45061344 0.38553518 0.16385134] Label: 1 Wrong\n",
      "Probability: [0.23580146 0.19598746 0.56821114] Label: 2\n",
      "Probability: [0.46919674 0.4029232  0.12788004] Label: 1 Wrong\n",
      "Probability: [0.4839229  0.41748494 0.09859216] Label: 0\n",
      "Probability: [0.51916146 0.45889828 0.02194021] Label: 0\n",
      "Probability: [0.34522927 0.29051235 0.36425838] Label: 2\n",
      "Probability: [0.47686276 0.4103905  0.11274677] Label: 0\n",
      "Probability: [0.43885624 0.3742182  0.18692558] Label: 0\n",
      "Probability: [0.47389564 0.4074049  0.11869945] Label: 0\n",
      "Probability: [0.41423935 0.35182995 0.23393072] Label: 1 Wrong\n",
      "Probability: [0.1918989  0.15884629 0.6492548 ] Label: 2\n",
      "Probability: [0.24152328 0.20089796 0.55757874] Label: 2\n",
      "Probability: [0.33747333 0.28368115 0.37884548] Label: 0 Wrong\n",
      "Probability: [0.428576   0.36493614 0.20648785] Label: 0\n",
      "Probability: [0.3495008  0.2942476  0.35625163] Label: 0 Wrong\n",
      "Probability: [0.22675772 0.18833582 0.58490646] Label: 1 Wrong\n",
      "Probability: [0.36280698 0.30581787 0.33137518] Label: 2 Wrong\n",
      "Probability: [0.33865088 0.28462788 0.3767212 ] Label: 2\n",
      "Probability: [0.39463547 0.3343256  0.27103898] Label: 0\n",
      "Probability: [0.34119904 0.28707683 0.37172413] Label: 1 Wrong\n",
      "Probability: [0.30702433 0.25709057 0.43588507] Label: 2\n",
      "Probability: [0.24209768 0.20140941 0.55649287] Label: 1 Wrong\n",
      "Probability: [0.45319012 0.38761    0.15919983] Label: 1 Wrong\n",
      "Probability: [0.46053442 0.39475018 0.14471538] Label: 0\n",
      "Probability: [0.46099728 0.3951366  0.1438661 ] Label: 1 Wrong\n",
      "Probability: [0.4275966  0.3638179  0.20858549] Label: 1 Wrong\n",
      "Probability: [0.3871604  0.32757849 0.28526115] Label: 1 Wrong\n",
      "Probability: [0.44412613 0.37918425 0.17668962] Label: 2 Wrong\n",
      "Probability: [0.46151945 0.39553162 0.14294893] Label: 0\n",
      "Probability: [0.45014343 0.38477075 0.16508585] Label: 1 Wrong\n",
      "Probability: [0.240286   0.19980383 0.5599102 ] Label: 2\n",
      "Probability: [0.43604752 0.37169284 0.1922596 ] Label: 2 Wrong\n",
      "Probability: [0.36393458 0.3068531  0.3292124 ] Label: 2 Wrong\n",
      "Probability: [0.44816604 0.3828139  0.16902006] Label: 0\n",
      "Probability: [0.3818015  0.32271406 0.29548445] Label: 1 Wrong\n",
      "Probability: [0.42512476 0.3617329  0.2131423 ] Label: 1 Wrong\n",
      "Probability: [0.41614053 0.3534877  0.23037173] Label: 0\n",
      "Probability: [0.38212565 0.3229018  0.29497257] Label: 2 Wrong\n",
      "Probability: [0.48595756 0.4194394  0.09460313] Label: 0\n",
      "Probability: [0.39935026 0.33835468 0.26229507] Label: 1 Wrong\n",
      "Probability: [0.24272175 0.20190066 0.5553776 ] Label: 2\n",
      "Probability: [0.50266135 0.4373202  0.06001842] Label: 1 Wrong\n",
      "Probability: [0.4262666  0.36265573 0.21107765] Label: 1 Wrong\n",
      "Probability: [0.45735824 0.39148614 0.15115559] Label: 1 Wrong\n",
      "Probability: [0.4566044  0.39097345 0.15242215] Label: 0\n",
      "Probability: [0.26460692 0.22064741 0.5147457 ] Label: 2\n",
      "Probability: [0.36712787 0.3098107  0.32306144] Label: 0\n",
      "Probability: [0.3423169  0.28787258 0.36981052] Label: 2\n",
      "Probability: [0.3309574  0.27801466 0.39102802] Label: 0 Wrong\n",
      "Probability: [0.23715526 0.19716984 0.56567496] Label: 2\n",
      "Probability: [0.4725738  0.4062429  0.12118327] Label: 0\n",
      "Probability: [0.46707734 0.40095568 0.13196696] Label: 0\n",
      "Probability: [0.22084394 0.18335888 0.5957971 ] Label: 2\n",
      "Probability: [0.34006903 0.28586677 0.3740642 ] Label: 2\n",
      "Probability: [0.50811136 0.4436233  0.04826526] Label: 0\n",
      "Probability: [0.51690984 0.45507613 0.028014  ] Label: 1 Wrong\n",
      "Probability: [0.44439176 0.37938583 0.17622244] Label: 0\n",
      "Probability: [0.48698366 0.42050898 0.09250735] Label: 0\n",
      "Probability: [0.39602563 0.3353759  0.26859847] Label: 0\n",
      "Probability: [0.48805538 0.42155463 0.09038997] Label: 0\n",
      "Probability: [0.23970582 0.1993813  0.56091285] Label: 2\n",
      "Probability: [0.31214184 0.2620394  0.4258188 ] Label: 2\n",
      "Probability: [0.47938162 0.41289192 0.1077264 ] Label: 0\n",
      "Probability: [0.32158476 0.26976663 0.40864852] Label: 2\n",
      "Probability: [0.23287547 0.19351348 0.573611  ] Label: 0 Wrong\n",
      "Probability: [0.21537486 0.178674   0.6059512 ] Label: 2\n",
      "Probability: [0.47194228 0.40544778 0.12260988] Label: 1 Wrong\n",
      "Probability: [0.22722602 0.1887483  0.5840257 ] Label: 2\n",
      "Probability: [0.49107242 0.42485142 0.0840762 ] Label: 1 Wrong\n",
      "Probability: [0.4068155  0.34506667 0.24811786] Label: 2 Wrong\n",
      "Probability: [0.29063183 0.24303304 0.46633515] Label: 1 Wrong\n",
      "Probability: [0.4987999  0.43300578 0.06819432] Label: 1 Wrong\n",
      "Probability: [0.438851   0.3745711  0.18657789] Label: 0\n",
      "Probability: [0.43902513 0.3744977  0.1864771 ] Label: 1 Wrong\n",
      "Probability: [0.19872583 0.16458842 0.6366857 ] Label: 2\n",
      "Probability: [0.44999555 0.38477126 0.1652332 ] Label: 0\n",
      "Probability: [0.52270883 0.46846431 0.00882684] Label: 1 Wrong\n",
      "Probability: [0.36915502 0.31152412 0.31932083] Label: 1 Wrong\n",
      "Probability: [0.48952368 0.42322862 0.08724771] Label: 0\n",
      "Probability: [0.31584918 0.26480222 0.41934863] Label: 2\n",
      "Probability: [0.21874936 0.18154475 0.5997059 ] Label: 2\n",
      "Probability: [0.37164253 0.31367946 0.314678  ] Label: 2 Wrong\n",
      "Probability: [0.46628636 0.40016308 0.13355055] Label: 1 Wrong\n",
      "Probability: [0.4941713  0.42795834 0.07787035] Label: 0\n",
      "Probability: [0.3038835  0.25445038 0.44166607] Label: 1 Wrong\n",
      "Probability: [0.26407218 0.22018787 0.51574   ] Label: 0 Wrong\n",
      "Probability: [0.37755495 0.31900623 0.3034388 ] Label: 0\n",
      "Probability: [0.39334816 0.33307973 0.2735721 ] Label: 0\n",
      "Probability: [0.36527604 0.30794775 0.3267762 ] Label: 0\n",
      "Probability: [0.27281702 0.22772567 0.4994573 ] Label: 2\n",
      "Probability: [0.50164837 0.4358435  0.06250817] Label: 1 Wrong\n",
      "Probability: [0.19944902 0.16518873 0.6353622 ] Label: 2\n",
      "Probability: [0.45007926 0.3845505  0.1653702 ] Label: 0\n",
      "Probability: [0.3489832  0.29372728 0.35728952] Label: 2\n",
      "Probability: [0.40007898 0.3389349  0.26098615] Label: 2 Wrong\n",
      "Probability: [0.24889404 0.2072251  0.5438809 ] Label: 2\n",
      "Probability: [0.38287807 0.32378715 0.2933348 ] Label: 0\n",
      "Probability: [0.34337324 0.28873476 0.36789197] Label: 1 Wrong\n",
      "Probability: [0.46900302 0.40281662 0.1281803 ] Label: 0\n",
      "Probability: [0.22041866 0.18296513 0.5966162 ] Label: 2\n",
      "Probability: [0.3169646  0.26586875 0.41716668] Label: 0 Wrong\n",
      "Probability: [0.21402583 0.17749076 0.60848343] Label: 2\n",
      "Probability: [0.43128318 0.36719832 0.20151855] Label: 1 Wrong\n",
      "Probability: [0.4988714  0.43295014 0.06817849] Label: 0\n",
      "Probability: [0.31290454 0.26226726 0.42482823] Label: 1 Wrong\n",
      "Probability: [0.40102863 0.33982375 0.25914758] Label: 1 Wrong\n",
      "Probability: [0.34619087 0.29133308 0.362476  ] Label: 1 Wrong\n",
      "Probability: [0.4967291  0.43057215 0.07269872] Label: 0\n",
      "Probability: [0.42819026 0.3644657  0.20734401] Label: 1 Wrong\n",
      "Probability: [0.37549424 0.31704593 0.30745983] Label: 1 Wrong\n",
      "Probability: [0.44929725 0.3838891  0.16681363] Label: 0\n",
      "Probability: [0.47197738 0.4054142  0.12260847] Label: 0\n",
      "Probability: [0.34353438 0.28894776 0.3675179 ] Label: 2\n",
      "Probability: [0.50302273 0.43747708 0.05950025] Label: 1 Wrong\n",
      "Probability: [0.3851308  0.32563588 0.2892333 ] Label: 1 Wrong\n",
      "Probability: [0.26983285 0.22509423 0.5050729 ] Label: 0 Wrong\n",
      "Probability: [0.426896   0.3633971  0.20970689] Label: 1 Wrong\n",
      "Probability: [0.4987663  0.4329356  0.06829809] Label: 0\n",
      "Probability: [0.3555251  0.29942447 0.34505036] Label: 2 Wrong\n",
      "Probability: [0.30087605 0.25181708 0.44730687] Label: 2\n",
      "Probability: [0.33041412 0.27748963 0.3920962 ] Label: 2\n",
      "Probability: [0.36097908 0.304376   0.3346449 ] Label: 0\n",
      "Probability: [0.4316713  0.3677727  0.20055601] Label: 1 Wrong\n",
      "Probability: [0.44097087 0.37615085 0.1828783 ] Label: 0\n",
      "Probability: [0.3223781  0.27044755 0.40717432] Label: 2\n",
      "Probability: [0.3214364  0.26974857 0.40881503] Label: 2\n",
      "Probability: [0.4708562  0.40449205 0.12465172] Label: 0\n",
      "Probability: [0.44801548 0.3829729  0.16901152] Label: 1 Wrong\n",
      "Probability: [0.49507603 0.42891848 0.07600544] Label: 0\n",
      "Probability: [0.3506239  0.29532006 0.35405603] Label: 0 Wrong\n",
      "Probability: [0.43318892 0.3690171  0.19779402] Label: 0\n",
      "Probability: [0.30224064 0.2529594  0.44480002] Label: 1 Wrong\n",
      "Probability: [0.4733678  0.40709284 0.11953934] Label: 0\n",
      "Probability: [0.30797982 0.25796    0.43406013] Label: 2\n",
      "Probability: [0.4586697  0.39283288 0.1484974 ] Label: 0\n",
      "Probability: [0.41965184 0.3566181  0.22373006] Label: 1 Wrong\n",
      "Probability: [0.42658752 0.36296076 0.21045174] Label: 0\n",
      "Probability: [0.3257533  0.2734536  0.40079308] Label: 2\n",
      "Probability: [0.24339604 0.20249566 0.5541083 ] Label: 2\n",
      "Probability: [0.29968336 0.2509399  0.4493768 ] Label: 1 Wrong\n",
      "Probability: [0.41526595 0.35286167 0.23187244] Label: 0\n",
      "Probability: [0.40860003 0.34670556 0.24469432] Label: 0\n",
      "Probability: [0.26928538 0.22458524 0.5061293 ] Label: 2\n",
      "Probability: [0.46825817 0.4019981  0.12974377] Label: 1 Wrong\n",
      "Probability: [0.47465912 0.40810588 0.117235  ] Label: 0\n",
      "Probability: [0.52221155 0.46585634 0.01193204] Label: 1 Wrong\n",
      "Probability: [0.48441517 0.41792038 0.09766442] Label: 1 Wrong\n",
      "Probability: [0.3908235  0.33059508 0.27858135] Label: 2 Wrong\n",
      "Probability: [0.43225595 0.36827713 0.19946694] Label: 0\n",
      "Probability: [0.4977491  0.4319048  0.07034615] Label: 1 Wrong\n",
      "Probability: [0.33314872 0.27986825 0.38698304] Label: 1 Wrong\n",
      "Probability: [0.44972283 0.38449335 0.1657838 ] Label: 1 Wrong\n",
      "Probability: [0.2607443  0.2173275  0.52192825] Label: 0 Wrong\n",
      "Probability: [0.39221233 0.3319721  0.27581564] Label: 1 Wrong\n",
      "Probability: [0.42740858 0.36372378 0.20886756] Label: 0\n",
      "Probability: [0.22179404 0.18409657 0.5941094 ] Label: 2\n",
      "Probability: [0.39060348 0.3307326  0.27866387] Label: 0\n",
      "Probability: [0.24677832 0.20534997 0.54787177] Label: 2\n",
      "Probability: [0.44604516 0.38095543 0.17299943] Label: 1 Wrong\n",
      "Probability: [0.25952068 0.21630283 0.5241765 ] Label: 0 Wrong\n",
      "Probability: [0.25507262 0.21248174 0.53244567] Label: 2\n",
      "Probability: [0.45094126 0.38560313 0.16345553] Label: 0\n",
      "Probability: [0.27101487 0.22615664 0.5028285 ] Label: 2\n",
      "Probability: [0.38977537 0.32984525 0.28037938] Label: 1 Wrong\n",
      "Probability: [0.46452206 0.3983642  0.13711369] Label: 0\n",
      "Probability: [0.4774826  0.4112208  0.11129664] Label: 0\n",
      "Probability: [0.388074   0.3283747  0.28355128] Label: 0\n",
      "Probability: [0.2944795  0.24632134 0.45919922] Label: 0 Wrong\n",
      "Probability: [0.49081394 0.42446727 0.0847188 ] Label: 1 Wrong\n",
      "Probability: [0.4297602  0.36599693 0.20424286] Label: 0\n",
      "Probability: [0.2545271  0.21198629 0.53348666] Label: 2\n",
      "Probability: [0.21221393 0.17595643 0.61182964] Label: 2\n",
      "Probability: [0.4501224  0.3848666  0.16501106] Label: 0\n",
      "Probability: [0.50779575 0.44317216 0.04903204] Label: 0\n",
      "Probability: [0.5008201  0.4349588  0.06422114] Label: 1 Wrong\n",
      "Probability: [0.32046708 0.26881984 0.4107131 ] Label: 2\n",
      "Probability: [0.4747354  0.40836045 0.11690409] Label: 1 Wrong\n",
      "Probability: [0.46398014 0.3979048  0.13811503] Label: 2 Wrong\n",
      "Probability: [0.47792405 0.4113682  0.11070773] Label: 1 Wrong\n",
      "Probability: [0.41424623 0.35219315 0.23356068] Label: 2 Wrong\n",
      "Probability: [0.3877914  0.328029   0.28417963] Label: 0\n",
      "Probability: [0.23722357 0.19724807 0.5655283 ] Label: 2\n",
      "Probability: [0.49465978 0.4282982  0.07704195] Label: 1 Wrong\n",
      "Probability: [0.3583589  0.30226088 0.33938026] Label: 1 Wrong\n",
      "Probability: [0.37606826 0.31740287 0.30652887] Label: 0\n",
      "Probability: [0.41610226 0.3534073  0.2304905 ] Label: 0\n",
      "Probability: [0.24844801 0.20676903 0.544783  ] Label: 2\n",
      "Probability: [0.3502781 0.294903  0.3548189] Label: 1 Wrong\n",
      "Probability: [0.5166643  0.45424333 0.02909236] Label: 0\n",
      "Probability: [0.39234424 0.33210123 0.27555454] Label: 0\n",
      "Probability: [0.29254296 0.24469274 0.46276423] Label: 1 Wrong\n",
      "Probability: [0.32134384 0.26969954 0.40895662] Label: 2\n",
      "Probability: [0.4392788 0.3747553 0.1859659] Label: 1 Wrong\n",
      "Probability: [0.4529845  0.38745946 0.15955609] Label: 0\n",
      "Probability: [0.44478643 0.37987015 0.1753435 ] Label: 1 Wrong\n",
      "Probability: [0.4425009  0.3776783  0.17982076] Label: 0\n",
      "Probability: [0.21702279 0.18009418 0.6028831 ] Label: 2\n",
      "Probability: [0.3416402  0.2873882  0.37097156] Label: 0 Wrong\n",
      "Probability: [0.32061255 0.2689841  0.41040334] Label: 2\n",
      "Probability: [0.37944934 0.32063195 0.29991874] Label: 2 Wrong\n",
      "Probability: [0.39268324 0.33250448 0.2748122 ] Label: 0\n",
      "Probability: [0.22516064 0.1869902  0.58784914] Label: 2\n",
      "Probability: [0.4635986  0.39751738 0.13888404] Label: 1 Wrong\n",
      "Probability: [0.34042093 0.28616324 0.37341583] Label: 2\n",
      "Probability: [0.33670986 0.28289708 0.38039306] Label: 0 Wrong\n",
      "Probability: [0.31142142 0.2609393  0.42763928] Label: 2\n",
      "Probability: [0.3284089  0.27576694 0.3958242 ] Label: 1 Wrong\n",
      "Probability: [0.30154818 0.252428   0.44602385] Label: 1 Wrong\n",
      "Probability: [0.42723164 0.36364627 0.20912205] Label: 1 Wrong\n",
      "Probability: [0.3430385  0.28842762 0.36853388] Label: 2\n",
      "Probability: [0.3824176  0.3232753  0.29430714] Label: 2 Wrong\n",
      "Probability: [0.2910195  0.24330729 0.46567324] Label: 0 Wrong\n",
      "Probability: [0.48104754 0.4146413  0.10431117] Label: 1 Wrong\n",
      "Probability: [0.47517014 0.40863883 0.11619096] Label: 0\n",
      "Probability: [0.2423036  0.20153123 0.55616516] Label: 2\n",
      "Probability: [0.46640337 0.4000179  0.1335787 ] Label: 0\n",
      "Probability: [0.41021878 0.34812942 0.24165176] Label: 0\n",
      "Probability: [0.4667837  0.40058208 0.13263421] Label: 0\n",
      "Probability: [0.4499884  0.38468605 0.16532563] Label: 1 Wrong\n",
      "Probability: [0.23731041 0.19735684 0.5653328 ] Label: 2\n",
      "Probability: [0.3278879  0.27530316 0.39680895] Label: 2\n",
      "Probability: [0.32877868 0.27614406 0.3950773 ] Label: 0 Wrong\n",
      "Probability: [0.30812156 0.2583016  0.4335768 ] Label: 1 Wrong\n",
      "Probability: [0.5102461  0.44606316 0.0436907 ] Label: 0\n",
      "Probability: [0.28341854 0.23685384 0.47972766] Label: 0 Wrong\n",
      "Probability: [0.4123525  0.35002556 0.23762198] Label: 0\n",
      "Probability: [0.3124356  0.26185656 0.42570788] Label: 2\n",
      "Probability: [0.44996145 0.38468856 0.16535003] Label: 0\n",
      "Probability: [0.47415403 0.40783224 0.11801376] Label: 1 Wrong\n",
      "Probability: [0.46225896 0.39611626 0.14162476] Label: 0\n",
      "Probability: [0.4125509  0.35032412 0.23712489] Label: 2 Wrong\n",
      "Probability: [0.30896643 0.2589185  0.43211505] Label: 0 Wrong\n",
      "Probability: [0.34510905 0.29041362 0.36447743] Label: 1 Wrong\n",
      "Probability: [0.2832674  0.23662901 0.48010352] Label: 2\n",
      "Probability: [0.22975071 0.19093278 0.57931656] Label: 2\n",
      "Probability: [0.20703322 0.1716246  0.6213421 ] Label: 2\n",
      "Probability: [0.19599852 0.16230978 0.6416917 ] Label: 0 Wrong\n",
      "Probability: [0.48957407 0.4229115  0.08751443] Label: 1 Wrong\n",
      "Probability: [0.47815502 0.41176608 0.11007896] Label: 1 Wrong\n",
      "Probability: [0.469026   0.40265277 0.12832116] Label: 0\n",
      "Probability: [0.24075952 0.20022276 0.55901766] Label: 2\n",
      "Probability: [0.44864595 0.38331422 0.16803986] Label: 0\n",
      "Probability: [0.48178244 0.4153047  0.10291279] Label: 1 Wrong\n",
      "Probability: [0.37324348 0.31507668 0.3116798 ] Label: 0\n",
      "Probability: [0.4761199  0.40960756 0.11427251] Label: 1 Wrong\n",
      "Probability: [0.4967694  0.4310209  0.07220963] Label: 1 Wrong\n",
      "Probability: [0.39648697 0.33585683 0.2676562 ] Label: 0\n",
      "Probability: [0.40006575 0.33894762 0.26098672] Label: 0\n",
      "Probability: [0.3262209 0.2738786 0.3999005] Label: 2\n",
      "Probability: [0.41908935 0.3563062  0.22460447] Label: 2 Wrong\n",
      "Probability: [0.35542643 0.2992938  0.3452798 ] Label: 2 Wrong\n",
      "Probability: [0.19973263 0.16544445 0.6348229 ] Label: 2\n",
      "Probability: [0.3152065  0.26420647 0.420587  ] Label: 1 Wrong\n",
      "Probability: [0.2507655  0.20882231 0.5404121 ] Label: 0 Wrong\n",
      "Probability: [0.3104192  0.26009464 0.4294862 ] Label: 1 Wrong\n",
      "Probability: [0.41067526 0.34858832 0.2407364 ] Label: 1 Wrong\n",
      "Probability: [0.39693555 0.33620784 0.2668566 ] Label: 0\n",
      "Probability: [0.23285547 0.19349292 0.5736517 ] Label: 0 Wrong\n",
      "Probability: [0.30250612 0.2532466  0.44424725] Label: 2\n",
      "Probability: [0.5058751  0.44089404 0.0532308 ] Label: 1 Wrong\n",
      "Probability: [0.49561623 0.429637   0.07474668] Label: 0\n",
      "Probability: [0.3567931  0.30064866 0.34255823] Label: 0\n",
      "Probability: [0.33090672 0.27797374 0.39111954] Label: 0 Wrong\n",
      "Probability: [0.4825218  0.41588467 0.10159353] Label: 0\n",
      "Probability: [0.34347537 0.28898165 0.36754304] Label: 2\n",
      "Probability: [0.34773728 0.2925623  0.35970035] Label: 2\n",
      "Probability: [0.24056569 0.20012066 0.55931365] Label: 0 Wrong\n",
      "Probability: [0.3056323  0.2560869  0.43828082] Label: 2\n",
      "Probability: [0.25608283 0.21329924 0.53061795] Label: 2\n",
      "Probability: [0.38751778 0.3278908  0.28459135] Label: 0\n",
      "Probability: [0.4683979  0.40214154 0.12946057] Label: 1 Wrong\n",
      "Probability: [0.35715494 0.30099505 0.34185004] Label: 1 Wrong\n",
      "Probability: [0.19662617 0.16282137 0.64055246] Label: 2\n",
      "Probability: [0.4600805  0.39412233 0.1457972 ] Label: 1 Wrong\n",
      "Probability: [0.43620393 0.3719741  0.1918219 ] Label: 1 Wrong\n",
      "Probability: [0.47181746 0.40547618 0.12270638] Label: 0\n",
      "Probability: [0.43021616 0.3664113  0.20337252] Label: 2 Wrong\n",
      "Probability: [0.3652887  0.30806223 0.32664913] Label: 1 Wrong\n",
      "Probability: [0.43599045 0.37205765 0.19195193] Label: 0\n",
      "Probability: [0.43990734 0.3752853  0.18480739] Label: 1 Wrong\n",
      "Probability: [0.38608223 0.32646286 0.2874549 ] Label: 0\n",
      "Probability: [0.35915416 0.30263737 0.33820847] Label: 0\n",
      "Probability: [0.48100236 0.41464815 0.10434958] Label: 1 Wrong\n",
      "Probability: [0.2456831  0.20448326 0.5498337 ] Label: 2\n",
      "Probability: [0.5042275  0.43906015 0.05671234] Label: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': 0.5334928, 'average_loss': 0.93127906, 'loss': 0.93127906, 'global_step': 15000}\n"
     ]
    }
   ],
   "source": [
    "#Linear Classifier\n",
    "test_probabilities_linear_classifier = test_classifier_model(linear_classifier, test_examples, test_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 2 Wrong\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 2 Wrong\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 2 Wrong\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 2 Wrong\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 0\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 2 Wrong\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 1 Wrong\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 0\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 1 Wrong\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 0\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 0\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 0\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 1 Wrong\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 0\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 1 Wrong\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 2 Wrong\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 2 Wrong\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 0\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 1 Wrong\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 0\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 2 Wrong\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 0\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 1 Wrong\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 2 Wrong\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 0\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 2 Wrong\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 0\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 1 Wrong\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 0\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 2 Wrong\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 0\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 1 Wrong\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 1 Wrong\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 0\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 2 Wrong\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 2 Wrong\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 0\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 2 Wrong\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 2 Wrong\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 0\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 0\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 0\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 2 Wrong\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 2 Wrong\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 1 Wrong\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 2 Wrong\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 2 Wrong\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 0\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 0\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 0\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 2 Wrong\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 2 Wrong\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 2 Wrong\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 1 Wrong\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 1 Wrong\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 2 Wrong\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 0\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 2 Wrong\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 2 Wrong\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 1 Wrong\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 1 Wrong\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 1 Wrong\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 0\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 2 Wrong\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 0\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 0\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 1 Wrong\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 1 Wrong\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 0\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 1 Wrong\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 0\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 2 Wrong\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 0\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 1 Wrong\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 0\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 2 Wrong\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 1 Wrong\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 0\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 0\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 0\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 1 Wrong\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 1 Wrong\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 0\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 2 Wrong\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 0\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 2 Wrong\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 1 Wrong\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 0\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 1 Wrong\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 1 Wrong\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 2 Wrong\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 1 Wrong\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 0\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 1 Wrong\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 2 Wrong\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 1 Wrong\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 1 Wrong\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 1 Wrong\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 1 Wrong\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 0\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 2 Wrong\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 2 Wrong\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 2 Wrong\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 1 Wrong\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 1 Wrong\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 0\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 2 Wrong\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 0\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 1 Wrong\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 1 Wrong\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 0\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 1 Wrong\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 0\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 0\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 0\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 0\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 2 Wrong\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 2 Wrong\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 0\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 1 Wrong\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 2 Wrong\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 2 Wrong\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 0\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 1 Wrong\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 0\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 2 Wrong\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 2 Wrong\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 2 Wrong\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 1 Wrong\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 1 Wrong\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 1 Wrong\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 2 Wrong\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 2 Wrong\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 1 Wrong\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 2 Wrong\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 1 Wrong\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 0\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 0\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 2 Wrong\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 0\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 0\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 0\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 1 Wrong\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 2 Wrong\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 2 Wrong\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 0\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 0\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 0\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 1 Wrong\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 2 Wrong\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 2 Wrong\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 0\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 1 Wrong\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 2 Wrong\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 1 Wrong\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 1 Wrong\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 0\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 1 Wrong\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 1 Wrong\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 1 Wrong\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 2 Wrong\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 0\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 1 Wrong\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 2 Wrong\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 2 Wrong\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 2 Wrong\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 0\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 1 Wrong\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 1 Wrong\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 0\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 2 Wrong\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 0\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 1 Wrong\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 2 Wrong\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 1 Wrong\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 1 Wrong\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 1 Wrong\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 0\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 2 Wrong\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 0\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 2 Wrong\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 0\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 2 Wrong\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 0\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 0\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 2 Wrong\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 2 Wrong\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 0\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 1 Wrong\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 0\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 0\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 0\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 0\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 2 Wrong\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 2 Wrong\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 0\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 2 Wrong\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 0\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 2 Wrong\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 1 Wrong\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 2 Wrong\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 1 Wrong\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 2 Wrong\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 1 Wrong\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 1 Wrong\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 0\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 1 Wrong\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 2 Wrong\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 0\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 1 Wrong\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 1 Wrong\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 0\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 2 Wrong\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 2 Wrong\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 2 Wrong\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 1 Wrong\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 0\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 1 Wrong\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 0\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 0\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 0\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 0\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 2 Wrong\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 1 Wrong\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 2 Wrong\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 0\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 2 Wrong\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 2 Wrong\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 2 Wrong\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 0\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 1 Wrong\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 0\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 2 Wrong\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 0\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 2 Wrong\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 1 Wrong\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 0\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 1 Wrong\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 1 Wrong\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 1 Wrong\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 0\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 1 Wrong\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 1 Wrong\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 0\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 0\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 2 Wrong\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 1 Wrong\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 1 Wrong\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 0\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 1 Wrong\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 0\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 2 Wrong\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 2 Wrong\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 2 Wrong\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 0\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 1 Wrong\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 0\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 2 Wrong\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 2 Wrong\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 0\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 1 Wrong\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 0\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 0\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 0\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 1 Wrong\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 0\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 2 Wrong\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 0\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 1 Wrong\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 0\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 2 Wrong\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 2 Wrong\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 1 Wrong\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 0\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 0\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 2 Wrong\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 1 Wrong\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 0\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 1 Wrong\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 1 Wrong\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 2 Wrong\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 0\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 1 Wrong\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 1 Wrong\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 1 Wrong\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 0\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 1 Wrong\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 0\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 2 Wrong\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 0\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 2 Wrong\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 1 Wrong\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 0\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 2 Wrong\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 0\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 2 Wrong\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 1 Wrong\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 0\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 0\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 0\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 0\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 1 Wrong\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 0\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 2 Wrong\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 2 Wrong\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 0\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 0\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 1 Wrong\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 2 Wrong\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 1 Wrong\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 2 Wrong\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 1 Wrong\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 2 Wrong\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 0\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 2 Wrong\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 1 Wrong\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 1 Wrong\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 0\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 0\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 2 Wrong\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 1 Wrong\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 0\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 0\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 1 Wrong\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 2 Wrong\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 1 Wrong\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 0\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 1 Wrong\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 0\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 2 Wrong\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 0\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 2 Wrong\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 2 Wrong\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 0\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 2 Wrong\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 1 Wrong\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 2 Wrong\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 0\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 2 Wrong\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 1 Wrong\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 1 Wrong\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 1 Wrong\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 2 Wrong\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 2 Wrong\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 0\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 1 Wrong\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 0\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 2 Wrong\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 0\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 0\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 0\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 1 Wrong\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 2 Wrong\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 2 Wrong\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 0\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 1 Wrong\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 0\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 0\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 0\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 2 Wrong\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 0\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 1 Wrong\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 0\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 2 Wrong\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 0\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 1 Wrong\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 2 Wrong\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 2 Wrong\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 2 Wrong\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 0\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 1 Wrong\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 1 Wrong\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 0\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 2 Wrong\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 0\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 1 Wrong\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 0\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 1 Wrong\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 1 Wrong\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 0\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 0\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 2 Wrong\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 2 Wrong\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 2 Wrong\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 2 Wrong\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 1 Wrong\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 0\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 1 Wrong\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 1 Wrong\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 0\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 0\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 2 Wrong\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 1 Wrong\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 0\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 0\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 0\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 0\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 2 Wrong\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 2 Wrong\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 0\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 2 Wrong\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 2 Wrong\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 0\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 1 Wrong\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 1 Wrong\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 2 Wrong\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 1 Wrong\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 1 Wrong\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 0\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 2 Wrong\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 1 Wrong\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 0\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 1 Wrong\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 0\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 0\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 1 Wrong\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 2 Wrong\n",
      "Probability: [0.3654023  0.31272554 0.32187214] Label: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': 0.37799042, 'average_loss': 1.0944803, 'loss': 1.0944803, 'global_step': 15000}\n"
     ]
    }
   ],
   "source": [
    "#DNN Classifier\n",
    "test_probabilities_dnn_classifier = test_classifier_model(dnn_classifier, test_examples, test_targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Additional Info**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global_step 15000\n",
      "linear/linear_model/bias_weights [-0.36427435 -0.55326504  0.9175389 ]\n",
      "linear/linear_model/diameter/weights [[ 0.03310388  0.03059333 -0.06369696]]\n",
      "linear/linear_model/height/weights [[ 0.01917045  0.03207209 -0.05124255]]\n",
      "linear/linear_model/length/weights [[ 0.01711713  0.01185497 -0.02897207]]\n",
      "linear/linear_model/whole-weight/weights [[ 0.6484295  0.6794187 -1.3278475]]\n"
     ]
    }
   ],
   "source": [
    "#Linear Classifier Weights\n",
    "for v in linear_classifier.get_variable_names():\n",
    "    print(v, linear_classifier.get_variable_value(v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dnn/hiddenlayer_0/bias \n",
      " [0. 0. 0. 0. 0.]\n",
      "dnn/hiddenlayer_0/kernel \n",
      " [[ 0.7097728  -0.0618729  -0.08509386  0.7137395   0.18627131]\n",
      " [ 0.70141745  0.05438322  0.31876683  0.48590314  0.7818954 ]\n",
      " [-0.5962707   0.41421604  0.44987357 -0.52498835  0.35252988]\n",
      " [-0.5216064   0.6338352   0.7826561   0.65573204  0.71445143]]\n",
      "dnn/hiddenlayer_1/bias \n",
      " [0. 0. 0. 0.]\n",
      "dnn/hiddenlayer_1/kernel \n",
      " [[ 0.4358431   0.33241796 -0.38178864 -0.37363303]\n",
      " [ 0.27835965  0.28887308  0.29125476 -0.63849497]\n",
      " [-0.78618973  0.12776566  0.3125645   0.5418292 ]\n",
      " [-0.45248407 -0.81028515 -0.8137919   0.18014187]\n",
      " [-0.5472272  -0.7826437  -0.6874985  -0.5242881 ]]\n",
      "dnn/hiddenlayer_2/bias \n",
      " [0. 0. 0.]\n",
      "dnn/hiddenlayer_2/kernel \n",
      " [[ 0.59462965  0.7658385  -0.33671802]\n",
      " [-0.1793738  -0.04830295  0.5041379 ]\n",
      " [-0.32100475 -0.14016902  0.6273323 ]\n",
      " [ 0.31957507  0.5035      0.11883724]]\n",
      "dnn/logits/bias \n",
      " [ 0.09417247 -0.06150053 -0.03267211]\n",
      "dnn/logits/kernel \n",
      " [[ 0.205127    0.16545987 -0.2844212 ]\n",
      " [-0.39368415 -0.29556036  0.03838897]\n",
      " [-0.8779814  -0.44069314 -0.69294   ]]\n",
      "global_step \n",
      " 15000\n"
     ]
    }
   ],
   "source": [
    "#DNN Classifier Weights\n",
    "for v in dnn_classifier.get_variable_names():\n",
    "    print(v, \"\\n\", dnn_classifier.get_variable_value(v))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
